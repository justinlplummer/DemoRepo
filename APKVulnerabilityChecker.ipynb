{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/justinlplummer/DemoRepo/blob/master/APKVulnerabilityChecker.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bgeByOnx3yPs"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "!pip install androguard\n",
        "!apt-get install apktool -y\n",
        "# --- Setup directories ---\n",
        "# Define the base directory for reports\n",
        "# Create directories if missing\n",
        "os.makedirs(\"apks\", exist_ok=True)\n",
        "os.makedirs(\"reports\", exist_ok=True) # Ensure the reports directory exists\n",
        "\n",
        "print(f\"Before continuing, APKs should be placed in: {'apks/'}\")\n",
        "print(f\"Reports will be generated in: {'reports/'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUrfcX2y1bV_",
        "outputId": "c4680603-557d-4647-882e-4baca0034bd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rScanning APKs:   0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Report generated for Grindr - Gay Dating & Chat_25.12.1_APKPure at reports/Grindr - Gay Dating & Chat_25.12.1_APKPure_report/report.html\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Scanning APKs: 100%|██████████| 1/1 [01:55<00:00, 115.82s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Done! Check the 'reports/' folder for results.\n"
          ]
        }
      ],
      "source": [
        "# Full APK Vulnerability Scanner with Real Cloud Service Scans\n",
        "# Google Colab compatible, no placeholders\n",
        "\n",
        "\n",
        "import sys\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import zipfile\n",
        "import shutil\n",
        "import tempfile\n",
        "import requests\n",
        "import xml.etree.ElementTree as ET\n",
        "from datetime import datetime\n",
        "from androguard.core.apk import APK\n",
        "from tqdm import tqdm\n",
        "\n",
        "from loguru import logger\n",
        "logger.remove()\n",
        "\n",
        "# Regex patterns to detect cloud services URLs or endpoints in strings extracted from APK\n",
        "CLOUD_SERVICES = {\n",
        "    'firebase': r'https?://[\\w\\-.]+\\.firebaseio\\.com',\n",
        "    'aws': r'https?://s3[.-][a-z0-9-]*\\.amazonaws\\.com|https?://[\\w\\-]+\\.s3\\.amazonaws\\.com',\n",
        "    'gcp': r'https?://storage\\.googleapis\\.com|https?://[\\w\\-]+\\.storage\\.googleapis\\.com',\n",
        "    'azure': r'https?://[\\w\\-]+\\.blob\\.core\\.windows\\.net',\n",
        "    'backblaze': r'https?://f[0-9]+\\.backblazeb2\\.com',\n",
        "    'wasabi': r'https?://s3\\.wasabisys\\.com',\n",
        "    'supabase': r'https?://[\\w\\-]+\\.supabase\\.co',\n",
        "    'heroku': r'https?://[\\w\\-]+\\.herokuapp\\.com',\n",
        "    'netlify': r'https?://[\\w\\-]+\\.netlify\\.app',\n",
        "    'vercel': r'https?://[\\w\\-]+\\.vercel\\.app',\n",
        "    'digitalocean': r'https?://[\\w\\-]+\\.digitaloceanspaces\\.com',\n",
        "    'linode': r'https?://[\\w\\-]+\\.linodeobjects\\.com',\n",
        "    'ibm': r'https?://[\\w\\-]+\\.cloud-object-storage\\.appdomain\\.cloud',\n",
        "    'oracle': r'https?://objectstorage\\.[a-z\\-]+\\.oraclecloud\\.com',\n",
        "    'minio': r'https?://[\\w\\-\\.]+/minio',\n",
        "    'cloudflare': r'https?://[\\w\\-]+\\.r2\\.cloudflarestorage\\.com',\n",
        "    'parse': r'https?://[\\w\\-]+\\.back4app\\.io',\n",
        "    'kinvey': r'https?://[\\w\\-]+\\.kinvey\\.com',\n",
        "    'packetfabric': r'https?://[\\w\\-]+\\.packetfabric\\.com',\n",
        "}\n",
        "\n",
        "# Regex patterns for common API keys, secrets, tokens inside APK strings\n",
        "SECRETS_REGEX = [\n",
        "    (r\"AIza[0-9A-Za-z\\-_]{35}\", \"Google API Key\"),\n",
        "    (r\"[a-zA-Z0-9_]{32,45}-us[0-9]+\", \"Mailchimp API Key\"),\n",
        "    (r\"AKIA[0-9A-Z]{16}\", \"AWS Access Key ID\"),\n",
        "    (r\"(?<![A-Z0-9])[A-Z0-9]{20}(?![A-Z0-9])\", \"Generic API Key\"),\n",
        "    (r\"(?<![a-z0-9])[a-z0-9]{32}(?![a-z0-9])\", \"Generic Secret\"),\n",
        "    # Facebook App Secret (typically 32 lowercase hex characters)\n",
        "    (r\"(?<![a-f0-9])[a-f0-9]{32}(?![a-f0-9])(?=[^a-zA-Z0-9]*facebook|fb_app_secret|app_secret)\", \"Facebook App Secret (Potential)\"), # Added lookahead for context\n",
        "\n",
        "    # Twitter Consumer Secret (typically 45 characters, alphanumeric + underscore/dash)\n",
        "    (r\"[0-9a-zA-Z\\-_]{45}(?=[^a-zA-Z0-9]*(twitter|consumer_secret|oauth_consumer_secret))\", \"Twitter Consumer Secret (Potential)\"), # Added lookahead for context\n",
        "\n",
        "    # Google OAuth Client Secret (similar to generic secrets, but often has specific lengths or starts/ends differently)\n",
        "    # This is tricky because Google Client Secrets for *web apps* are diverse.\n",
        "    # If found in an APK, it's almost always a critical error.\n",
        "    # Example: GOCSPX-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx (can be 38 chars after prefix, or other forms)\n",
        "    (r\"GOCSPX-[0-9A-Za-z\\-_]{38}\", \"Google OAuth Client Secret (Potential)\"),\n",
        "    # General pattern for 'client_secret' followed by a strong candidate value\n",
        "    (r\"(client_secret|oauth_client_secret|app_secret)[\\s=:]*[\\\"']?([a-zA-Z0-9\\-_]{32,64})[\\\"']?\", \"OAuth Client Secret (Generic Key-Value)\"), # Catches common \"key=value\" pairs\n",
        "\n",
        "    # Refresh Tokens (long-lived, highly sensitive) - often start with 1/ or 1//\n",
        "    (r\"1\\/[0-9A-Za-z\\-_]{40,}\", \"Google OAuth Refresh Token (Potential)\"),\n",
        "    (r\"ya29\\.[0-9A-Za-z\\-_]+\", \"Google OAuth Access/Refresh Token (Potential)\"),\n",
        "\n",
        "    # Common Client IDs (less severe if found, but good to identify if context suggests misuse)\n",
        "    # Google Client ID example: 123456789012-abcdefg12345.apps.googleusercontent.com\n",
        "    (r\"\\b\\d{12}-[\\w]{20,}\\.apps\\.googleusercontent\\.com\\b\", \"Google OAuth Client ID\"),\n",
        "    # Facebook App ID (purely numeric, public)\n",
        "    (r\"\\b(facebook_app_id|fb_app_id)[\\s=:]*[\\\"']?(\\d{15,17})[\\\"']?\", \"Facebook App ID\"),\n",
        "]\n",
        "\n",
        "def extract_strings(file_path):\n",
        "    # Extract readable ASCII strings 4+ chars long from APK binary\n",
        "    with open(file_path, 'rb') as f:\n",
        "        content = f.read()\n",
        "    raw_strings = re.findall(rb'[\\x20-\\x7E]{4,}', content)\n",
        "    return [s.decode(errors='ignore') for s in raw_strings]\n",
        "\n",
        "def detect_cloud_services(strings):\n",
        "    detected = {}\n",
        "    for service, pattern in CLOUD_SERVICES.items():\n",
        "        regex = re.compile(pattern, re.IGNORECASE)\n",
        "        found_urls = set()\n",
        "        for s in strings:\n",
        "            matches = regex.findall(s)\n",
        "            if matches:\n",
        "                found_urls.update(matches)\n",
        "        if found_urls:\n",
        "            detected[service] = list(found_urls)\n",
        "    return detected\n",
        "\n",
        "def detect_secrets(strings):\n",
        "    findings = []\n",
        "    for s in strings:\n",
        "        for pattern, name in SECRETS_REGEX:\n",
        "            if re.search(pattern, s):\n",
        "                findings.append({\"type\": name, \"value\": s})\n",
        "    return findings\n",
        "\n",
        "\n",
        "\n",
        "# =====================\n",
        "# XML Vulnerability Scans\n",
        "# =====================\n",
        "\n",
        "def scan_manifest_vulnerabilities(decompiled_path, findings, app_id):\n",
        "    \"\"\"\n",
        "    Scans AndroidManifest.xml for common vulnerabilities like debuggable flag,\n",
        "    cleartext traffic, and insecurely exported components.\n",
        "    \"\"\"\n",
        "    manifest_path = os.path.join(decompiled_path, \"AndroidManifest.xml\")\n",
        "    if not os.path.exists(manifest_path):\n",
        "        logger.warning(f\"AndroidManifest.xml not found at {manifest_path}\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        tree = ET.parse(manifest_path)\n",
        "        root = tree.getroot()\n",
        "        # Define Android namespace for XPath queries\n",
        "        ns = {'android': 'http://schemas.android.com/apk/res/android'}\n",
        "\n",
        "        # 1. Check for android:debuggable=\"true\"\n",
        "        application_tag = root.find('application')\n",
        "        if application_tag is not None:\n",
        "            debuggable = application_tag.get(f\"{{{ns['android']}}}debuggable\")\n",
        "            if debuggable == 'true':\n",
        "                findings.append({\n",
        "                    \"service\": \"AndroidManifest\",\n",
        "                    \"url\": \"N/A\",\n",
        "                    \"issue\": \"Application is debuggable\",\n",
        "                    \"severity\": \"CRITICAL\",\n",
        "                    \"remediation\": \"Set android:debuggable to 'false' in production builds. This exposes the app to debugging tools and potential data extraction.\"\n",
        "                })\n",
        "\n",
        "            # 2. Check for android:usesCleartextTraffic=\"true\"\n",
        "            uses_cleartext_traffic = application_tag.get(f\"{{{ns['android']}}}usesCleartextTraffic\")\n",
        "            if uses_cleartext_traffic == 'true':\n",
        "                findings.append({\n",
        "                    \"service\": \"AndroidManifest\",\n",
        "                    \"url\": \"N/A\",\n",
        "                    \"issue\": \"Application allows cleartext HTTP traffic\",\n",
        "                    \"severity\": \"HIGH\",\n",
        "                    \"remediation\": \"Ensure all network communication uses HTTPS. Cleartext traffic is vulnerable to eavesdropping and tampering. Consider a Network Security Configuration to enforce HTTPS.\"\n",
        "                })\n",
        "\n",
        "        # 3. Check for insecurely exported components\n",
        "        exported_components = root.findall(\".//*[@android:exported='true']\", ns)\n",
        "        for component in exported_components:\n",
        "            # Check if component is an activity, service, receiver, or provider\n",
        "            if component.tag in ['activity', 'service', 'receiver', 'provider']:\n",
        "                # Check if a permission is explicitly defined for the component\n",
        "                has_permission = component.get(f\"{{{ns['android']}}}permission\") is not None\n",
        "                if not has_permission:\n",
        "                    name = component.get(f\"{{{ns['android']}}}name\")\n",
        "                    findings.append({\n",
        "                        \"service\": \"AndroidManifest\",\n",
        "                        \"url\": \"N/A\",\n",
        "                        \"issue\": f\"Exported {component.tag} '{name}' without explicit permission\",\n",
        "                        \"severity\": \"CRITICAL\",\n",
        "                        \"remediation\": f\"Either set android:exported='false' for {component.tag} '{name}' or add a strong android:permission attribute to restrict access by other applications.\"\n",
        "                    })\n",
        "\n",
        "    except ET.ParseError as e:\n",
        "        logger.error(f\"Error parsing AndroidManifest.xml: {e}\")\n",
        "        findings.append({\n",
        "            \"service\": \"AndroidManifest\",\n",
        "            \"url\": \"N/A\",\n",
        "            \"issue\": f\"Error parsing AndroidManifest.xml: {e}\",\n",
        "            \"severity\": \"LOW\",\n",
        "            \"remediation\": \"Check APK integrity or parsing logic.\"\n",
        "        })\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Unexpected error in scan_manifest_vulnerabilities: {e}\")\n",
        "\n",
        "\n",
        "def scan_insecure_storage_patterns(decompiled_path, findings, app_id):\n",
        "    \"\"\"\n",
        "    Scans common storage locations (like SharedPreferences XML files) for sensitive keywords.\n",
        "    Note: This is a static analysis heuristic. Actual runtime data storage would require dynamic analysis.\n",
        "    \"\"\"\n",
        "    sensitive_keywords = [\"password\", \"token\", \"secret\", \"api_key\", \"credential\", \"auth\", \"sessionid\", \"pin\"]\n",
        "\n",
        "    # Common paths for SharedPreferences XML files in decompiled APK\n",
        "    # These are usually under res/xml or sometimes in asset folders.\n",
        "    # For runtime data, they'd be in /data/data/{package_name}/shared_prefs/\n",
        "    # This static check focuses on bundled/default prefs or those found in resources.\n",
        "    search_dirs = [\n",
        "        os.path.join(decompiled_path, \"res\", \"xml\"),\n",
        "        os.path.join(decompiled_path, \"assets\")\n",
        "    ]\n",
        "\n",
        "    for root_dir in search_dirs:\n",
        "        if not os.path.exists(root_dir):\n",
        "            continue\n",
        "        for root, _, files in os.walk(root_dir):\n",
        "            for file in files:\n",
        "                if file.endswith(\".xml\") or file.endswith(\".json\"): # SharedPreferences are XML, but other configs might be JSON\n",
        "                    file_path = os.path.join(root, file)\n",
        "                    try:\n",
        "                        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
        "                            content = f.read().lower()\n",
        "                            for keyword in sensitive_keywords:\n",
        "                                if keyword in content:\n",
        "                                    findings.append({\n",
        "                                        \"service\": \"Insecure Data Storage\",\n",
        "                                        \"url\": f\"file://{os.path.relpath(file_path, decompiled_path)}\",\n",
        "                                        \"issue\": f\"Sensitive keyword '{keyword}' found in {file}. Potential insecure storage.\",\n",
        "                                        \"severity\": \"HIGH\",\n",
        "                                        \"remediation\": \"Avoid storing sensitive data in plaintext in SharedPreferences or other accessible files. Use Android Keystore or encrypted storage solutions.\"\n",
        "                                    })\n",
        "                                    break # Only report once per file for the first keyword found\n",
        "                    except Exception as e:\n",
        "                        logger.warning(f\"Could not read/parse {file_path}: {e}\")\n",
        "\n",
        "def scan_weak_cryptography(strings, findings, app_id):\n",
        "    \"\"\"\n",
        "    Heuristically checks for mentions of weak cryptographic algorithms or hardcoded keys\n",
        "    within extracted strings. Reports each *type* of weakness only once.\n",
        "    \"\"\"\n",
        "    weak_algorithms_data = {\n",
        "        \"MD5\": \"MD5 is cryptographically broken and should not be used for hashing passwords or verifying integrity.\",\n",
        "        \"SHA1\": \"SHA-1 is cryptographically broken and should not be used for digital signatures or integrity checks.\",\n",
        "        \"DES\": \"Data Encryption Standard (DES) is insecure due to its small key size.\",\n",
        "        \"RC4\": \"RC4 is a stream cipher with known vulnerabilities and should be avoided.\",\n",
        "        \"ECB mode\": \"Electronic Codebook (ECB) mode is insecure for encryption as identical plaintext blocks produce identical ciphertext blocks.\",\n",
        "    }\n",
        "\n",
        "    key_patterns_data = [\n",
        "        (\"hardcoded key (generic)\", r\"(key|secret|passphrase)[\\s=:]*[\\\"']?([a-zA-Z0-9]{16,128})[\\\"']?\"), # Generic key pattern\n",
        "        (\"hardcoded key (SecretKeySpec)\", r\"new SecretKeySpec\\s*\\((.*?)\\)\"), # Java SecretKeySpec constructor\n",
        "    ]\n",
        "\n",
        "    reported_weaknesses = set() # To store unique weakness identifiers (e.g., \"MD5\", \"hardcoded key (generic)\")\n",
        "\n",
        "    for s in strings:\n",
        "        # Check for weak algorithms\n",
        "        for algo, desc in weak_algorithms_data.items():\n",
        "            if algo.lower() in s.lower():\n",
        "                if algo not in reported_weaknesses:\n",
        "                    findings.append({\n",
        "                        \"service\": \"Weak Cryptography\",\n",
        "                        \"url\": \"N/A\",\n",
        "                        \"issue\": f\"Potential use of weak cryptographic algorithm: {algo}. {desc}\",\n",
        "                        \"severity\": \"HIGH\",\n",
        "                        \"remediation\": f\"Migrate to stronger algorithms (e.g., AES-256 with GCM, SHA-256/SHA-3 for hashing, PBKDF2/scrypt/bcrypt for passwords) and proper modes of operation (e.g., CBC, GCM).\"\n",
        "                    })\n",
        "                    reported_weaknesses.add(algo)\n",
        "                # No 'break' here, as a single string might contain multiple weak algorithms\n",
        "\n",
        "        # Check for hardcoded keys (distinct from weak algorithms)\n",
        "        for key_type, pattern in key_patterns_data:\n",
        "            if re.search(pattern, s, re.IGNORECASE):\n",
        "                if key_type not in reported_weaknesses:\n",
        "                    findings.append({\n",
        "                        \"service\": \"Weak Cryptography\",\n",
        "                        \"url\": \"N/A\",\n",
        "                        \"issue\": f\"Potential {key_type} detected. This makes the key easily extractable.\",\n",
        "                        \"severity\": \"CRITICAL\",\n",
        "                        \"remediation\": \"Never hardcode encryption keys. Use Android Keystore, derive keys securely, or fetch them from a trusted backend.\"\n",
        "                    })\n",
        "                    reported_weaknesses.add(key_type)\n",
        "                # No 'break' here, as a single string might contain multiple key patterns\n",
        "\n",
        "\n",
        "\n",
        "# =====================\n",
        "# Cloud service scanners\n",
        "# Each takes (urls: list[str], findings: list, app_id: str)\n",
        "# and appends dicts with findings to findings list\n",
        "# =====================\n",
        "\n",
        "def scan_firebase(urls, findings, app_id):\n",
        "    for url in urls:\n",
        "        test_url = url.rstrip('/') + '/.json'\n",
        "        try:\n",
        "            r = requests.get(test_url, timeout=10)\n",
        "            if r.status_code == 200:\n",
        "                findings.append({\n",
        "                    \"service\": \"Firebase\",\n",
        "                    \"url\": test_url,\n",
        "                    \"issue\": \"Publicly readable Firebase Realtime Database endpoint\",\n",
        "                    \"severity\": \"CRITICAL\",\n",
        "                    \"remediation\": \"Configure Firebase database rules to restrict public access.\"\n",
        "                })\n",
        "            elif r.status_code == 403:\n",
        "                findings.append({\n",
        "                    \"service\": \"Firebase\",\n",
        "                    \"url\": test_url,\n",
        "                    \"issue\": \"Firebase endpoint requires authentication (secure).\",\n",
        "                    \"severity\": \"INFO\",\n",
        "                    \"remediation\": \"No public exposure detected.\"\n",
        "                })\n",
        "            else:\n",
        "                findings.append({\n",
        "                    \"service\": \"Firebase\",\n",
        "                    \"url\": test_url,\n",
        "                    \"issue\": f\"Unexpected HTTP status code {r.status_code}\",\n",
        "                    \"severity\": \"LOW\",\n",
        "                    \"remediation\": \"Investigate response status.\"\n",
        "                })\n",
        "        except Exception as e:\n",
        "            findings.append({\n",
        "                \"service\": \"Firebase\",\n",
        "                \"url\": test_url,\n",
        "                \"issue\": f\"Error accessing Firebase endpoint: {e}\",\n",
        "                \"severity\": \"LOW\",\n",
        "                \"remediation\": \"Check network and URL correctness.\"\n",
        "            })\n",
        "\n",
        "def scan_aws(urls, findings, app_id):\n",
        "    # Try to list S3 bucket if URL points to root or bucket endpoint\n",
        "    for url in urls:\n",
        "        try:\n",
        "            r = requests.get(url, timeout=10)\n",
        "            if r.status_code == 200 and \"<ListBucketResult\" in r.text:\n",
        "                findings.append({\n",
        "                    \"service\": \"AWS S3\",\n",
        "                    \"url\": url,\n",
        "                    \"issue\": \"Publicly listable S3 bucket\",\n",
        "                    \"severity\": \"CRITICAL\",\n",
        "                    \"remediation\": \"Apply bucket policies or block public access.\"\n",
        "                })\n",
        "            elif r.status_code == 403:\n",
        "                findings.append({\n",
        "                    \"service\": \"AWS S3\",\n",
        "                    \"url\": url,\n",
        "                    \"issue\": \"S3 bucket access forbidden (likely secure)\",\n",
        "                    \"severity\": \"INFO\",\n",
        "                    \"remediation\": \"No public exposure detected.\"\n",
        "                })\n",
        "            else:\n",
        "                findings.append({\n",
        "                    \"service\": \"AWS S3\",\n",
        "                    \"url\": url,\n",
        "                    \"issue\": f\"HTTP status {r.status_code} from bucket URL\",\n",
        "                    \"severity\": \"LOW\",\n",
        "                    \"remediation\": \"Review bucket permissions.\"\n",
        "                })\n",
        "        except Exception as e:\n",
        "            findings.append({\n",
        "                \"service\": \"AWS S3\",\n",
        "                \"url\": url,\n",
        "                \"issue\": f\"Error accessing S3 bucket: {e}\",\n",
        "                \"severity\": \"LOW\",\n",
        "                \"remediation\": \"Check bucket URL and network.\"\n",
        "            })\n",
        "\n",
        "def scan_gcp(urls, findings, app_id):\n",
        "    for url in urls:\n",
        "        try:\n",
        "            r = requests.get(url, timeout=10)\n",
        "            # For GCP buckets, if public listing allowed, response will contain <ListBucketResult> or JSON\n",
        "            if r.status_code == 200:\n",
        "                # Simplified heuristic: if response contains \"items\", bucket contents may be public\n",
        "                if \"items\" in r.text or \"ListBucketResult\" in r.text:\n",
        "                    findings.append({\n",
        "                        \"service\": \"Google Cloud Storage\",\n",
        "                        \"url\": url,\n",
        "                        \"issue\": \"Publicly readable GCP storage bucket\",\n",
        "                        \"severity\": \"CRITICAL\",\n",
        "                        \"remediation\": \"Set bucket IAM policies to restrict public access.\"\n",
        "                    })\n",
        "                else:\n",
        "                    findings.append({\n",
        "                        \"service\": \"Google Cloud Storage\",\n",
        "                        \"url\": url,\n",
        "                        \"issue\": \"Bucket reachable but no clear listing detected\",\n",
        "                        \"severity\": \"INFO\",\n",
        "                        \"remediation\": \"Review bucket permissions manually.\"\n",
        "                    })\n",
        "            elif r.status_code == 403:\n",
        "                findings.append({\n",
        "                    \"service\": \"Google Cloud Storage\",\n",
        "                    \"url\": url,\n",
        "                    \"issue\": \"Access forbidden, likely secure\",\n",
        "                    \"severity\": \"INFO\",\n",
        "                    \"remediation\": \"No public exposure.\"\n",
        "                })\n",
        "            else:\n",
        "                findings.append({\n",
        "                    \"service\": \"Google Cloud Storage\",\n",
        "                    \"url\": url,\n",
        "                    \"issue\": f\"HTTP status {r.status_code}\",\n",
        "                    \"severity\": \"LOW\",\n",
        "                    \"remediation\": \"Check bucket configuration.\"\n",
        "                })\n",
        "        except Exception as e:\n",
        "            findings.append({\n",
        "                \"service\": \"Google Cloud Storage\",\n",
        "                \"url\": url,\n",
        "                \"issue\": f\"Error accessing bucket: {e}\",\n",
        "                \"severity\": \"LOW\",\n",
        "                \"remediation\": \"Check URL/network.\"\n",
        "            })\n",
        "\n",
        "def scan_azure(urls, findings, app_id):\n",
        "    for url in urls:\n",
        "        try:\n",
        "            # Azure blob URL usually ends with container or blob name; test container-level access\n",
        "            r = requests.get(url, timeout=10)\n",
        "            if r.status_code == 200 and (\"<?xml\" in r.text and \"<EnumerationResults\" in r.text):\n",
        "                findings.append({\n",
        "                    \"service\": \"Azure Blob Storage\",\n",
        "                    \"url\": url,\n",
        "                    \"issue\": \"Publicly listable Azure blob container\",\n",
        "                    \"severity\": \"CRITICAL\",\n",
        "                    \"remediation\": \"Restrict blob container public access.\"\n",
        "                })\n",
        "            elif r.status_code == 403:\n",
        "                findings.append({\n",
        "                    \"service\": \"Azure Blob Storage\",\n",
        "                    \"url\": url,\n",
        "                    \"issue\": \"Access forbidden (likely secure)\",\n",
        "                    \"severity\": \"INFO\",\n",
        "                    \"remediation\": \"No public exposure detected.\"\n",
        "                })\n",
        "            else:\n",
        "                findings.append({\n",
        "                    \"service\": \"Azure Blob Storage\",\n",
        "                    \"url\": url,\n",
        "                    \"issue\": f\"Unexpected HTTP status {r.status_code}\",\n",
        "                    \"severity\": \"LOW\",\n",
        "                    \"remediation\": \"Review permissions.\"\n",
        "                })\n",
        "        except Exception as e:\n",
        "            findings.append({\n",
        "                \"service\": \"Azure Blob Storage\",\n",
        "                \"url\": url,\n",
        "                \"issue\": f\"Error accessing blob storage: {e}\",\n",
        "                \"severity\": \"LOW\",\n",
        "                \"remediation\": \"Check network/URL.\"\n",
        "            })\n",
        "\n",
        "def scan_backblaze(urls, findings, app_id):\n",
        "    for url in urls:\n",
        "        try:\n",
        "            r = requests.get(url, timeout=10)\n",
        "            if r.status_code == 200:\n",
        "                findings.append({\n",
        "                    \"service\": \"Backblaze B2\",\n",
        "                    \"url\": url,\n",
        "                    \"issue\": \"Accessible Backblaze B2 bucket (public files possible)\",\n",
        "                    \"severity\": \"MEDIUM\",\n",
        "                    \"remediation\": \"Check bucket policies and ACLs.\"\n",
        "                })\n",
        "            elif r.status_code == 403:\n",
        "                findings.append({\n",
        "                    \"service\": \"Backblaze B2\",\n",
        "                    \"url\": url,\n",
        "                    \"issue\": \"Access forbidden (likely secure)\",\n",
        "                    \"severity\": \"INFO\",\n",
        "                    \"remediation\": \"No public exposure.\"\n",
        "                })\n",
        "            else:\n",
        "                findings.append({\n",
        "                    \"service\": \"Backblaze B2\",\n",
        "                    \"url\": url,\n",
        "                    \"issue\": f\"HTTP status {r.status_code}\",\n",
        "                    \"severity\": \"LOW\",\n",
        "                    \"remediation\": \"Review bucket.\"\n",
        "                })\n",
        "        except Exception as e:\n",
        "            findings.append({\n",
        "                \"service\": \"Backblaze B2\",\n",
        "                \"url\": url,\n",
        "                \"issue\": f\"Error accessing bucket: {e}\",\n",
        "                \"severity\": \"LOW\",\n",
        "                \"remediation\": \"Check URL/network.\"\n",
        "            })\n",
        "\n",
        "def scan_wasabi(urls, findings, app_id):\n",
        "    # Wasabi is S3-compatible, reuse aws scan logic\n",
        "    scan_aws(urls, findings, app_id)\n",
        "\n",
        "def scan_supabase(urls, findings, app_id):\n",
        "    for url in urls:\n",
        "        # Supabase is a Postgres backend, check anon key presence or public access endpoint\n",
        "        for url in urls:\n",
        "            if \"anon\" in url.lower():\n",
        "                findings.append({\n",
        "                    \"service\": \"Supabase\",\n",
        "                    \"url\": url,\n",
        "                    \"issue\": \"Supabase anon key or public API endpoint detected\",\n",
        "                    \"severity\": \"HIGH\",\n",
        "                    \"remediation\": \"Rotate anon keys and secure APIs.\"\n",
        "                })\n",
        "            else:\n",
        "                findings.append({\n",
        "                    \"service\": \"Supabase\",\n",
        "                    \"url\": url,\n",
        "                    \"issue\": \"Supabase endpoint found, manual review needed\",\n",
        "                    \"severity\": \"INFO\",\n",
        "                    \"remediation\": \"Check supabase project security.\"\n",
        "                })\n",
        "\n",
        "def scan_heroku(urls, findings, app_id):\n",
        "    for url in urls:\n",
        "        # Scan for exposed debug pages or env vars (simple heuristic: check landing page content)\n",
        "        try:\n",
        "            r = requests.get(url, timeout=10)\n",
        "            if r.status_code == 200 and (\"heroku\" in r.text.lower() or \"application error\" in r.text.lower()):\n",
        "                findings.append({\n",
        "                    \"service\": \"Heroku\",\n",
        "                    \"url\": url,\n",
        "                    \"issue\": \"Heroku app reachable; check for debug info exposure\",\n",
        "                    \"severity\": \"MEDIUM\",\n",
        "                    \"remediation\": \"Review Heroku app config and error page exposure.\"\n",
        "                })\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "def scan_netlify(urls, findings, app_id):\n",
        "    for url in urls:\n",
        "        # Check if .env or config files are accessible publicly\n",
        "        env_url = url.rstrip('/') + \"/.env\"\n",
        "        try:\n",
        "            r = requests.get(env_url, timeout=10)\n",
        "            if r.status_code == 200 and (\"KEY=\" in r.text or \"SECRET\" in r.text):\n",
        "                findings.append({\n",
        "                    \"service\": \"Netlify\",\n",
        "                    \"url\": env_url,\n",
        "                    \"issue\": \"Exposed .env file with secrets\",\n",
        "                    \"severity\": \"CRITICAL\",\n",
        "                    \"remediation\": \"Remove .env from public web root.\"\n",
        "                })\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "def scan_vercel(urls, findings, app_id):\n",
        "    for url in urls:\n",
        "        # Check for common config files exposed\n",
        "        try:\n",
        "            config_url = url.rstrip('/') + \"/api/_vercel_build_output\"\n",
        "            r = requests.get(config_url, timeout=10)\n",
        "            if r.status_code == 200:\n",
        "                findings.append({\n",
        "                    \"service\": \"Vercel\",\n",
        "                    \"url\": config_url,\n",
        "                    \"issue\": \"Potentially exposed Vercel build output\",\n",
        "                    \"severity\": \"MEDIUM\",\n",
        "                    \"remediation\": \"Secure build artifact endpoints.\"\n",
        "                })\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "def scan_digitalocean(urls, findings, app_id):\n",
        "    for url in urls:\n",
        "        try:\n",
        "            r = requests.get(url, timeout=10)\n",
        "            if r.status_code == 200:\n",
        "                findings.append({\n",
        "                    \"service\": \"DigitalOcean Spaces\",\n",
        "                    \"url\": url,\n",
        "                    \"issue\": \"Accessible DigitalOcean space; check ACLs\",\n",
        "                    \"severity\": \"MEDIUM\",\n",
        "                    \"remediation\": \"Review and tighten space permissions.\"\n",
        "                })\n",
        "            elif r.status_code == 403:\n",
        "                findings.append({\n",
        "                    \"service\": \"DigitalOcean Spaces\",\n",
        "                    \"url\": url,\n",
        "                    \"issue\": \"Access forbidden; likely secure\",\n",
        "                    \"severity\": \"INFO\",\n",
        "                    \"remediation\": \"No public exposure.\"\n",
        "                })\n",
        "        except Exception as e:\n",
        "            findings.append({\n",
        "                \"service\": \"DigitalOcean Spaces\",\n",
        "                \"url\": url,\n",
        "                \"issue\": f\"Error accessing space: {e}\",\n",
        "                \"severity\": \"LOW\",\n",
        "                \"remediation\": \"Check URL/network.\"\n",
        "            })\n",
        "\n",
        "def scan_linode(urls, findings, app_id):\n",
        "    for url in urls:\n",
        "        try:\n",
        "            r = requests.get(url, timeout=10)\n",
        "            if r.status_code == 200:\n",
        "                findings.append({\n",
        "                    \"service\": \"Linode Object Storage\",\n",
        "                    \"url\": url,\n",
        "                    \"issue\": \"Accessible Linode bucket; review ACLs\",\n",
        "                    \"severity\": \"MEDIUM\",\n",
        "                    \"remediation\": \"Review bucket permissions.\"\n",
        "                })\n",
        "            elif r.status_code == 403:\n",
        "                findings.append({\n",
        "                    \"service\": \"Linode Object Storage\",\n",
        "                    \"url\": url,\n",
        "                    \"issue\": \"Access forbidden; likely secure\",\n",
        "                    \"severity\": \"INFO\",\n",
        "                    \"remediation\": \"No public exposure.\"\n",
        "                })\n",
        "        except Exception as e:\n",
        "            findings.append({\n",
        "                \"service\": \"Linode Object Storage\",\n",
        "                \"url\": url,\n",
        "                \"issue\": f\"Error accessing bucket: {e}\",\n",
        "                \"severity\": \"LOW\",\n",
        "                \"remediation\": \"Check URL/network.\"\n",
        "            })\n",
        "\n",
        "def scan_ibm(urls, findings, app_id):\n",
        "    for url in urls:\n",
        "        try:\n",
        "            r = requests.get(url, timeout=10)\n",
        "            if r.status_code == 200:\n",
        "                findings.append({\n",
        "                    \"service\": \"IBM Cloud Object Storage\",\n",
        "                    \"url\": url,\n",
        "                    \"issue\": \"Accessible IBM Cloud bucket; review permissions\",\n",
        "                    \"severity\": \"MEDIUM\",\n",
        "                    \"remediation\": \"Review bucket IAM and CORS policies.\"\n",
        "                })\n",
        "            elif r.status_code == 403:\n",
        "                findings.append({\n",
        "                    \"service\": \"IBM Cloud Object Storage\",\n",
        "                    \"url\": url,\n",
        "                    \"issue\": \"Access forbidden; likely secure\",\n",
        "                    \"severity\": \"INFO\",\n",
        "                    \"remediation\": \"No public exposure.\"\n",
        "                })\n",
        "        except Exception as e:\n",
        "            findings.append({\n",
        "                \"service\": \"IBM Cloud Object Storage\",\n",
        "                \"url\": url,\n",
        "                \"issue\": f\"Error accessing bucket: {e}\",\n",
        "                \"severity\": \"LOW\",\n",
        "                \"remediation\": \"Check URL/network.\"\n",
        "            })\n",
        "\n",
        "def scan_oracle(urls, findings, app_id):\n",
        "    for url in urls:\n",
        "        try:\n",
        "            r = requests.get(url, timeout=10)\n",
        "            if r.status_code == 200:\n",
        "                findings.append({\n",
        "                    \"service\": \"Oracle Cloud Object Storage\",\n",
        "                    \"url\": url,\n",
        "                    \"issue\": \"Accessible Oracle bucket; review policies\",\n",
        "                    \"severity\": \"MEDIUM\",\n",
        "                    \"remediation\": \"Restrict public access.\"\n",
        "                })\n",
        "            elif r.status_code == 403:\n",
        "                findings.append({\n",
        "                    \"service\": \"Oracle Cloud Object Storage\",\n",
        "                    \"url\": url,\n",
        "                    \"issue\": \"Access forbidden; likely secure\",\n",
        "                    \"severity\": \"INFO\",\n",
        "                    \"remediation\": \"No public exposure.\"\n",
        "                })\n",
        "        except Exception as e:\n",
        "            findings.append({\n",
        "                \"service\": \"Oracle Cloud Object Storage\",\n",
        "                \"url\": url,\n",
        "                \"issue\": f\"Error accessing bucket: {e}\",\n",
        "                \"severity\": \"LOW\",\n",
        "                \"remediation\": \"Check URL/network.\"\n",
        "            })\n",
        "\n",
        "def scan_minio(urls, findings, app_id):\n",
        "    for url in urls:\n",
        "        try:\n",
        "            # MinIO often exposes web dashboards on port 9000 or specific paths\n",
        "            r = requests.get(url, timeout=10)\n",
        "            if r.status_code == 200 and (\"MinIO\" in r.text or \"minio\" in r.text):\n",
        "                findings.append({\n",
        "                    \"service\": \"MinIO\",\n",
        "                    \"url\": url,\n",
        "                    \"issue\": \"Accessible MinIO web dashboard or bucket\",\n",
        "                    \"severity\": \"HIGH\",\n",
        "                    \"remediation\": \"Secure MinIO endpoints and require authentication.\"\n",
        "                })\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "def scan_cloudflare(urls, findings, app_id):\n",
        "    for url in urls:\n",
        "        try:\n",
        "            r = requests.get(url, timeout=10)\n",
        "            if r.status_code == 200:\n",
        "                findings.append({\n",
        "                    \"service\": \"Cloudflare R2 Storage\",\n",
        "                    \"url\": url,\n",
        "                    \"issue\": \"Accessible Cloudflare R2 bucket; check ACLs\",\n",
        "                    \"severity\": \"MEDIUM\",\n",
        "                    \"remediation\": \"Review bucket policies.\"\n",
        "                })\n",
        "            elif r.status_code == 403:\n",
        "                findings.append({\n",
        "                    \"service\": \"Cloudflare R2 Storage\",\n",
        "                    \"url\": url,\n",
        "                    \"issue\": \"Access forbidden; likely secure\",\n",
        "                    \"severity\": \"INFO\",\n",
        "                    \"remediation\": \"No public exposure.\"\n",
        "                })\n",
        "        except Exception as e:\n",
        "            findings.append({\n",
        "                \"service\": \"Cloudflare R2 Storage\",\n",
        "                \"url\": url,\n",
        "                \"issue\": f\"Error accessing bucket: {e}\",\n",
        "                \"severity\": \"LOW\",\n",
        "                \"remediation\": \"Check URL/network.\"\n",
        "            })\n",
        "\n",
        "def scan_parse(urls, findings, app_id):\n",
        "    for url in urls:\n",
        "        # Parse / Back4App backend service, check for open classes or exposed app id\n",
        "        for url in urls:\n",
        "            if \"/classes/\" in url:\n",
        "                findings.append({\n",
        "                    \"service\": \"Parse / Back4App\",\n",
        "                    \"url\": url,\n",
        "                    \"issue\": \"Parse classes endpoint detected - check for public access\",\n",
        "                    \"severity\": \"HIGH\",\n",
        "                    \"remediation\": \"Secure Parse classes and API keys.\"\n",
        "                })\n",
        "            else:\n",
        "                findings.append({\n",
        "                    \"service\": \"Parse / Back4App\",\n",
        "                    \"url\": url,\n",
        "                    \"issue\": \"Parse endpoint found - manual review needed\",\n",
        "                    \"severity\": \"INFO\",\n",
        "                    \"remediation\": \"Check backend security.\"\n",
        "                })\n",
        "\n",
        "def scan_kinvey(urls, findings, app_id):\n",
        "    for url in urls:\n",
        "        # Kinvey is a mobile backend as a service - look for exposed collections or app keys\n",
        "        for url in urls:\n",
        "            if \"/appdata/\" in url or \"/appkey/\" in url:\n",
        "                findings.append({\n",
        "                    \"service\": \"Kinvey\",\n",
        "                    \"url\": url,\n",
        "                    \"issue\": \"Potential exposed Kinvey appdata or keys\",\n",
        "                    \"severity\": \"HIGH\",\n",
        "                    \"remediation\": \"Rotate keys and secure appdata endpoints.\"\n",
        "                })\n",
        "            else:\n",
        "                findings.append({\n",
        "                    \"service\": \"Kinvey\",\n",
        "                    \"url\": url,\n",
        "                    \"issue\": \"Kinvey endpoint found - manual review needed\",\n",
        "                    \"severity\": \"INFO\",\n",
        "                    \"remediation\": \"Review Kinvey app security.\"\n",
        "                })\n",
        "\n",
        "def scan_packetfabric(urls, findings, app_id):\n",
        "    for url in urls:\n",
        "        findings.append({\n",
        "            \"service\": \"PacketFabric\",\n",
        "            \"url\": url,\n",
        "            \"issue\": \"Detected PacketFabric cloud endpoint — manual security review recommended\",\n",
        "            \"severity\": \"INFO\",\n",
        "            \"remediation\": \"Check PacketFabric access controls and permissions.\"\n",
        "        })\n",
        "\n",
        "# Map cloud services to their scanner functions\n",
        "SCAN_FUNCTIONS = {\n",
        "    \"firebase\": scan_firebase,\n",
        "    \"aws\": scan_aws,\n",
        "    \"gcp\": scan_gcp,\n",
        "    \"azure\": scan_azure,\n",
        "    \"backblaze\": scan_backblaze,\n",
        "    \"wasabi\": scan_wasabi,\n",
        "    \"supabase\": scan_supabase,\n",
        "    \"heroku\": scan_heroku,\n",
        "    \"netlify\": scan_netlify,\n",
        "    \"vercel\": scan_vercel,\n",
        "    \"digitalocean\": scan_digitalocean,\n",
        "    \"linode\": scan_linode,\n",
        "    \"ibm\": scan_ibm,\n",
        "    \"oracle\": scan_oracle,\n",
        "    \"minio\": scan_minio,\n",
        "    \"cloudflare\": scan_cloudflare,\n",
        "    \"parse\": scan_parse,\n",
        "    \"kinvey\": scan_kinvey,\n",
        "    \"packetfabric\": scan_packetfabric,\n",
        "}\n",
        "\n",
        "def extract_firebase_project_ids(decompiled_path):\n",
        "    project_ids = set()\n",
        "\n",
        "    # Look for google-services.json\n",
        "    for root, _, files in os.walk(decompiled_path):\n",
        "        for file in files:\n",
        "            if file == 'google-services.json':\n",
        "                try:\n",
        "                    with open(os.path.join(root, file), 'r') as f:\n",
        "                        data = json.load(f)\n",
        "                        project_id = data.get(\"project_info\", {}).get(\"project_id\")\n",
        "                        if project_id:\n",
        "                            project_ids.add(project_id)\n",
        "                except Exception:\n",
        "                    pass\n",
        "\n",
        "    # Search in smali or XML for firebaseio or firebaseapp\n",
        "    for root, _, files in os.walk(decompiled_path):\n",
        "        for file in files:\n",
        "            if file.endswith('.smali') or file.endswith('.xml') or file.endswith('.json'):\n",
        "                try:\n",
        "                    with open(os.path.join(root, file), 'r', errors='ignore') as f:\n",
        "                        content = f.read()\n",
        "                        matches = re.findall(r'https?://([a-z0-9\\-]+)\\.firebaseio\\.com', content)\n",
        "                        matches += re.findall(r'https?://([a-z0-9\\-]+)\\.web\\.app', content)\n",
        "                        matches += re.findall(r'https?://([a-z0-9\\-]+)\\.firebaseapp\\.com', content)\n",
        "                        for match in matches:\n",
        "                            project_ids.add(match)\n",
        "                except Exception:\n",
        "                    continue\n",
        "\n",
        "    return list(project_ids)\n",
        "\n",
        "def scan_firebase_project(project_id):\n",
        "    findings = []\n",
        "\n",
        "    base_urls = {\n",
        "        \"Realtime DB\": f\"https://{project_id}.firebaseio.com/.json\",\n",
        "        \"Firestore\": f\"https://firestore.googleapis.com/v1/projects/{project_id}/databases/(default)/documents\",\n",
        "        \"Storage\": f\"https://storage.googleapis.com/storage/v1/b/{project_id}.appspot.com/o\",\n",
        "        \"Cloud Functions\": f\"https://{project_id}.cloudfunctions.net/\"\n",
        "    }\n",
        "\n",
        "    for service, url in base_urls.items():\n",
        "        try:\n",
        "            r = requests.get(url, timeout=8)\n",
        "            status_code = r.status_code # Renamed 'status' to 'status_code' to avoid conflict with the key 'status' in the dictionary below.\n",
        "            if status_code == 200:\n",
        "                findings.append({\n",
        "                    \"service\": \"Firebase \" + service, # Added \"Firebase \" prefix for clarity in report\n",
        "                    \"url\": url,\n",
        "                    \"issue\": f\"{service} is OPEN\",\n",
        "                    \"severity\": \"CRITICAL\",\n",
        "                    \"remediation\": f\"Configure Firebase {service} rules to restrict public access.\"\n",
        "                })\n",
        "            elif status_code in [401, 403]:\n",
        "                findings.append({\n",
        "                    \"service\": \"Firebase \" + service,\n",
        "                    \"url\": url,\n",
        "                    \"issue\": f\"{service} requires authentication (secure).\",\n",
        "                    \"severity\": \"INFO\",\n",
        "                    \"remediation\": \"No public exposure detected.\"\n",
        "                })\n",
        "            elif status_code == 404:\n",
        "                findings.append({\n",
        "                    \"service\": \"Firebase \" + service,\n",
        "                    \"url\": url,\n",
        "                    \"issue\": f\"{service} endpoint not found.\",\n",
        "                    \"severity\": \"INFO\",\n",
        "                    \"remediation\": \"Verify the endpoint URL or if the service is in use.\"\n",
        "                })\n",
        "            else:\n",
        "                findings.append({\n",
        "                    \"service\": \"Firebase \" + service,\n",
        "                    \"url\": url,\n",
        "                    \"issue\": f\"Unexpected HTTP status code {status_code} for {service}\",\n",
        "                    \"severity\": \"LOW\",\n",
        "                    \"remediation\": \"Investigate response status.\"\n",
        "                })\n",
        "        except requests.exceptions.Timeout:\n",
        "            findings.append({\n",
        "                \"service\": \"Firebase \" + service,\n",
        "                \"url\": url,\n",
        "                \"issue\": f\"Timeout connecting to {service} endpoint.\",\n",
        "                \"severity\": \"LOW\",\n",
        "                \"remediation\": \"Check network connectivity or if the endpoint is active.\"\n",
        "            })\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            findings.append({\n",
        "                \"service\": \"Firebase \" + service,\n",
        "                \"url\": url,\n",
        "                \"issue\": f\"Error accessing {service} endpoint: {str(e)}\",\n",
        "                \"severity\": \"LOW\",\n",
        "                \"remediation\": \"Check network and URL correctness.\"\n",
        "            })\n",
        "\n",
        "    return findings\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Main report generator\n",
        "def generate_report(apk_path):\n",
        "    tmpdir = tempfile.mkdtemp()\n",
        "    app_id = os.path.splitext(os.path.basename(apk_path))[0]\n",
        "    findings = []\n",
        "    vulnerability_findings = []\n",
        "\n",
        "    try:\n",
        "        # Handle XAPK extraction if needed\n",
        "        if apk_path.endswith(\".xapk\"):\n",
        "            with zipfile.ZipFile(apk_path, 'r') as z:\n",
        "                apk_files = [f for f in z.namelist() if f.endswith(\".apk\")]\n",
        "                if apk_files:\n",
        "                    z.extract(apk_files[0], tmpdir)\n",
        "                    apk_path_extracted = os.path.join(tmpdir, apk_files[0])\n",
        "                else:\n",
        "                    raise Exception(\"No APK found inside XAPK\")\n",
        "        else:\n",
        "            apk_path_extracted = apk_path\n",
        "\n",
        "        # Decompile APK with apktool for resource scanning\n",
        "        decompiled_dir = os.path.join(tmpdir, \"decompiled\")\n",
        "        os.makedirs(decompiled_dir, exist_ok=True)\n",
        "        os.system(f\"apktool d -f -o {decompiled_dir} {apk_path_extracted} > /dev/null 2>&1\")\n",
        "\n",
        "        # Extract Firebase project IDs from decompiled APK\n",
        "        project_ids = extract_firebase_project_ids(decompiled_dir)\n",
        "\n",
        "        # Scan Firebase projects for exposure\n",
        "        for pid in project_ids:\n",
        "            firebase_findings = scan_firebase_project(pid)\n",
        "            for finding in firebase_findings:\n",
        "                findings.append({\n",
        "                    \"service\": finding['service'], # Use the specific service name from scan_firebase_project\n",
        "                    \"url\": finding['url'],\n",
        "                    \"issue\": finding['issue'],\n",
        "                    \"severity\": finding['severity'],\n",
        "                    \"remediation\": finding['remediation']\n",
        "                })\n",
        "\n",
        "\n",
        "        apk = APK(apk_path_extracted)\n",
        "\n",
        "        # Extract strings from APK file for scanning\n",
        "        strings = extract_strings(apk_path_extracted)\n",
        "\n",
        "        # --- NEW SCANNERS INTEGRATION ---\n",
        "        scan_manifest_vulnerabilities(decompiled_dir, findings, app_id)\n",
        "        scan_insecure_storage_patterns(decompiled_dir, findings, app_id)\n",
        "        scan_weak_cryptography(strings, findings, app_id)\n",
        "        # --- END NEW SCANNERS INTEGRATION ---\n",
        "\n",
        "       # Detect secrets (API keys etc)\n",
        "        secrets_found = detect_secrets(strings)\n",
        "        aggragated_secrets = []\n",
        "        for secret in secrets_found:\n",
        "            if secret['type'] not in aggragated_secrets:\n",
        "                aggragated_secrets.append(secret['type'])\n",
        "                findings.append({\n",
        "                    \"service\": \"Secrets\",\n",
        "                    \"url\": \"\",\n",
        "                    \"issue\": f\"Possible secret/key detected: {secret['type']}\",\n",
        "                    \"severity\": \"HIGH\",\n",
        "                    \"remediation\": \"Remove secrets from code and use secure storage.\"\n",
        "                })\n",
        "\n",
        "\n",
        "        # Detect cloud services by regex on strings\n",
        "        cloud_services_found = detect_cloud_services(strings)\n",
        "\n",
        "\n",
        "\n",
        "        # Run cloud-specific scanners for each detected service\n",
        "        for svc, urls in cloud_services_found.items():\n",
        "            if svc in SCAN_FUNCTIONS:\n",
        "                SCAN_FUNCTIONS[svc](urls, findings, app_id)\n",
        "\n",
        "        # Generate HTML report\n",
        "        report_dir = f\"reports/{app_id}_report\"\n",
        "        os.makedirs(report_dir, exist_ok=True)\n",
        "\n",
        "        report_path = os.path.join(report_dir, \"report.html\")\n",
        "        with open(report_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(f\"<h1>Security Scan Report for {app_id}</h1>\\n\")\n",
        "            f.write(f\"<p>Scan Date: {datetime.utcnow().isoformat()} UTC</p>\\n\")\n",
        "            f.write(f\"<p><b>Package Name:</b> {apk.package}</p>\\n\")\n",
        "            f.write(f\"<p><b>Version:</b> {apk.get_androidversion_name() or 'Unknown'}</p>\")\n",
        "            f.write(f\"<p><b>Version:</b> {apk.get_androidversion_code() or 'Unknown'}</p>\")\n",
        "\n",
        "\n",
        "            f.write(\"<h2>Detected Secrets</h2>\\n\")\n",
        "            if secrets_found:\n",
        "                f.write(\"<ul>\\n\")\n",
        "                for secret in secrets_found:\n",
        "                    f.write(f\"<li>{secret['type']}: {secret['value'][:50]}...</li>\\n\")\n",
        "                f.write(\"</ul>\\n\")\n",
        "            else:\n",
        "                f.write(\"<p>None found.</p>\\n\")\n",
        "\n",
        "            f.write(\"<h2>Detected Cloud Services</h2>\\n\")\n",
        "            if cloud_services_found:\n",
        "                f.write(\"<ul>\\n\")\n",
        "                for svc, urls in cloud_services_found.items():\n",
        "                    f.write(f\"<li>{svc} ({len(urls)} URL(s))</li>\\n\")\n",
        "                f.write(\"</ul>\\n\")\n",
        "            else:\n",
        "                f.write(\"<p>No cloud services detected.</p>\\n\")\n",
        "\n",
        "            f.write(\"<h2>Vulnerability Findings</h2>\\n\")\n",
        "            if findings:\n",
        "                f.write(\"<ul>\\n\")\n",
        "                for issue in findings:\n",
        "                    f.write(\n",
        "                        f\"<li><b>{issue['service']}</b> - {issue['url']} - \"\n",
        "                        f\"{issue['issue']} <br>\"\n",
        "                        f\"<b>Severity:</b> {issue['severity']} <br>\"\n",
        "                        f\"<b>Remediation:</b> {issue['remediation']}</li>\\n\"\n",
        "                    )\n",
        "                f.write(\"</ul>\\n\")\n",
        "            else:\n",
        "                f.write(\"<p>No vulnerabilities detected.</p>\\n\")\n",
        "\n",
        "        print(f\"Report generated for {app_id} at {report_path}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {apk_path}: {e}\")\n",
        "\n",
        "    finally:\n",
        "        shutil.rmtree(tmpdir, ignore_errors=True)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    apk_files = [os.path.join(\"apks\", f) for f in os.listdir(\"apks\") if f.lower().endswith((\".apk\", \".xapk\"))]\n",
        "    for apk_file in tqdm(apk_files, desc=\"Scanning APKs\"):\n",
        "        generate_report(apk_file)\n",
        "\n",
        "    print(\"\\n✅ Done! Check the 'reports/' folder for results.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from datetime import datetime\n",
        "\n",
        "API_KEY = \"AIzaSyDD5Ceh8j-a6Xw2R_seA7d5FZ5W09PcGkI\"  # Replace with the API key you want to test\n",
        "\n",
        "# Define Google APIs to test\n",
        "google_api_tests = [\n",
        "    {\n",
        "        \"name\": \"YouTube Data API\",\n",
        "        \"url\": f\"https://www.googleapis.com/youtube/v3/videos?part=snippet&id=dQw4w9WgXcQ&key={API_KEY}\"\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Geocoding API\",\n",
        "        \"url\": f\"https://maps.googleapis.com/maps/api/geocode/json?address=1600+Amphitheatre+Parkway,+Mountain+View,+CA&key={API_KEY}\"\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Google Maps Elevation API\",\n",
        "        \"url\": f\"https://maps.googleapis.com/maps/api/elevation/json?locations=36.578581,-118.291994&key={API_KEY}\"\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Google Maps Static API\",\n",
        "        \"url\": f\"https://maps.googleapis.com/maps/api/staticmap?center=40.714224,-73.961452&zoom=15&size=600x300&key={API_KEY}\"\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Google Translate API\",\n",
        "        \"url\": f\"https://translation.googleapis.com/language/translate/v2?key={API_KEY}&q=hello&target=es\"\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Google Custom Search API\",\n",
        "        \"url\": f\"https://www.googleapis.com/customsearch/v1?q=test&key={API_KEY}&cx=017576662512468239146:omuauf_lfve\"\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Google Books API\",\n",
        "        \"url\": f\"https://www.googleapis.com/books/v1/volumes?q=isbn:0747532699&key={API_KEY}\"\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Google Safe Browsing API\",\n",
        "        \"url\": f\"https://safebrowsing.googleapis.com/v4/threatLists?key={API_KEY}\"\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Google Fonts API\",\n",
        "        \"url\": f\"https://www.googleapis.com/webfonts/v1/webfonts?key={API_KEY}\"\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Google Calendar API\",\n",
        "        \"url\": f\"https://www.googleapis.com/calendar/v3/users/me/calendarList?key={API_KEY}\"\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Google Drive API\",\n",
        "        \"url\": f\"https://www.googleapis.com/drive/v3/files?key={API_KEY}\"\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Google Sheets API\",\n",
        "        \"url\": f\"https://sheets.googleapis.com/v4/spreadsheets?key={API_KEY}\"\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Google Vision API\",\n",
        "        \"url\": f\"https://vision.googleapis.com/v1/images:annotate?key={API_KEY}\"\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Google Speech-to-Text API\",\n",
        "        \"url\": f\"https://speech.googleapis.com/v1/speech:recognize?key={API_KEY}\"\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Google Natural Language API\",\n",
        "        \"url\": f\"https://language.googleapis.com/v1/documents:analyzeEntities?key={API_KEY}\"\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Firebase Realtime Database (generic)\",\n",
        "        \"url\": f\"https://smule-com-api-project-293071437640.firebaseio.com/.json?key={API_KEY}\"\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Google Tag Manager API\",\n",
        "        \"url\": f\"https://www.googleapis.com/tagmanager/v2/accounts?key={API_KEY}\"\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Google Cloud Billing API\",\n",
        "        \"url\": f\"https://cloudbilling.googleapis.com/v1/billingAccounts?key={API_KEY}\"\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"anon account registry\",\n",
        "        \"url\": f\"https://identitytoolkit.googleapis.com/v1/accounts:signUp?key={API_KEY}\"\n",
        "\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"unauth login\",\n",
        "        \"url\": f\"https://identitytoolkit.googleapis.com/v1/accounts:signInWithPassword?key={API_KEY}\"\n",
        "\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"unauth acct lookup\",\n",
        "        \"url\": f\"https://identitytoolkit.googleapis.com/v1/accounts:lookup?key={API_KEY}\"\n",
        "\n",
        "    }\n",
        "]\n",
        "\n",
        "print(f\"🔍 Scanning Google API key: {API_KEY}\")\n",
        "print(f\"📅 Timestamp: {datetime.utcnow().isoformat()} UTC\\n\")\n",
        "\n",
        "for test in google_api_tests:\n",
        "    name, url = test[\"name\"], test[\"url\"]\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        if response.status_code == 200:\n",
        "            print(f\"[✅ ACCESS] {name}\")\n",
        "        elif response.status_code == 403:\n",
        "            print(f\"[🔒 FORBIDDEN] {name} – Access denied\")\n",
        "        elif response.status_code == 400:\n",
        "            print(f\"[⚠️ BAD REQUEST] {name} – Key accepted, but request malformed\")\n",
        "        elif response.status_code == 404:\n",
        "            print(f\"[❓ NOT FOUND] {name} – Endpoint may not be enabled\")\n",
        "        else:\n",
        "            print(f\"[❗ UNEXPECTED] {name} – Status: {response.status_code}\")\n",
        "    except Exception as e:\n",
        "        print(f\"[❌ ERROR] {name} – {str(e)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F91puDURMjOl",
        "outputId": "0aa84492-2977-4f6b-d11d-187059f23568"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Scanning Google API key: AIzaSyDD5Ceh8j-a6Xw2R_seA7d5FZ5W09PcGkI\n",
            "📅 Timestamp: 2025-07-31T03:57:49.969553 UTC\n",
            "\n",
            "[🔒 FORBIDDEN] YouTube Data API – Access denied\n",
            "[✅ ACCESS] Geocoding API\n",
            "[✅ ACCESS] Google Maps Elevation API\n",
            "[🔒 FORBIDDEN] Google Maps Static API – Access denied\n",
            "[🔒 FORBIDDEN] Google Translate API – Access denied\n",
            "[🔒 FORBIDDEN] Google Custom Search API – Access denied\n",
            "[🔒 FORBIDDEN] Google Books API – Access denied\n",
            "[🔒 FORBIDDEN] Google Safe Browsing API – Access denied\n",
            "[🔒 FORBIDDEN] Google Fonts API – Access denied\n",
            "[❗ UNEXPECTED] Google Calendar API – Status: 401\n",
            "[🔒 FORBIDDEN] Google Drive API – Access denied\n",
            "[❓ NOT FOUND] Google Sheets API – Endpoint may not be enabled\n",
            "[❓ NOT FOUND] Google Vision API – Endpoint may not be enabled\n",
            "[❓ NOT FOUND] Google Speech-to-Text API – Endpoint may not be enabled\n",
            "[❓ NOT FOUND] Google Natural Language API – Endpoint may not be enabled\n",
            "[❗ UNEXPECTED] Firebase Realtime Database (generic) – Status: 423\n",
            "[❗ UNEXPECTED] Google Tag Manager API – Status: 401\n",
            "[❗ UNEXPECTED] Google Cloud Billing API – Status: 401\n",
            "[❓ NOT FOUND] anon account registry – Endpoint may not be enabled\n",
            "[❓ NOT FOUND] unauth login – Endpoint may not be enabled\n",
            "[❓ NOT FOUND] unauth acct lookup – Endpoint may not be enabled\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMheZ8WaqfppTLwWtDfE2Ga",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}